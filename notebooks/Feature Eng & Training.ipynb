{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-monitor",
   "metadata": {},
   "source": [
    "# Feature Engineering & Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(14.7,7.27)})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "from config import majors, metrics, feat_cols, target_col\n",
    "from utils import create_rolling_agg_features_by_golfer, create_map_to_aggregates\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data\n",
    "scores = pd.read_csv('../data/historical_round_scores.csv')\n",
    "year = 2021\n",
    "tourney_name = 'bmw_championship'\n",
    "\n",
    "pre_tourney = pd.read_csv(f'../data/{year}_{tourney_name}_pre_tourney_snapshot.csv')\n",
    "pre_tourney.rename(columns={'bet365':'close_odds'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-minutes",
   "metadata": {},
   "source": [
    "## Data Processing and Creating new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laughing-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When did a golfer not finish a full event?\n",
    "# Cut, Withdrew, Disqualified, etc.\n",
    "early_outs = ['CUT','DQ','WD', 'W/D', 'MDF',]\n",
    "early_out_default = 75\n",
    "scores['early_out'] = np.where(scores.fin_text.isin(early_outs), 1, 0)\n",
    "\n",
    "#Cleaning up where a golfer finished a tournament\n",
    "#Making it numeric for use in the model\n",
    "scores['fin_num'] = (np.where(scores.fin_text.isin(early_outs),\n",
    "                             early_out_default,\n",
    "                             scores.fin_text.str.replace('T',''))\n",
    "                    ).astype(int)\n",
    "\n",
    "#Replacing Early Out Finishes with the Max finishing position per event\n",
    "scores['year_event_id'] = scores['year'].astype(str) + '_' + scores['event_id'].astype(str)\n",
    "max_fin_dict = create_map_to_aggregates(scores, 'year_event_id', 'fin_num', 'max')\n",
    "scores['fin_num'] = np.where(scores.fin_text.isin(early_outs),\n",
    "                             scores.year_event_id.map(max_fin_dict),\n",
    "                             scores.fin_num)\n",
    "\n",
    "#Filling in NULL close odds with avg per golfer\n",
    "mean_close_odds_per_golfer_dict = create_map_to_aggregates(scores, 'dg_id', 'close_odds', 'mean')\n",
    "scores['close_odds'] = np.where(pd.isnull(scores.close_odds),\n",
    "                                 scores.dg_id.map(mean_close_odds_per_golfer_dict),\n",
    "                                scores.close_odds)\n",
    "\n",
    "scores['close_odds'] = scores['close_odds'].fillna(scores.close_odds.quantile(.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "directed-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a unique year/event/golfer identifier\n",
    "scores['year_event_golfer'] = (scores['year'].astype(str) +\n",
    "                                      '_' + scores['event_id'].astype(str) +\n",
    "                                      '_' + scores['dg_id'].astype(str)\n",
    "                              )\n",
    "\n",
    "# Aggregating round data to an event level\n",
    "event_df = (scores.groupby(['dg_id','player_name','event_name',\n",
    "                            'event_id','fin_text','fin_num','early_out','close_odds',\n",
    "                            'year','year_event_id','year_event_golfer','event_completed',]).\n",
    "            agg(rounds=('round','count'),\n",
    "                mean_score = ('score', 'mean'),\n",
    "                mean_sg = ('sg_total', 'mean'),\n",
    "                total_sg = ('sg_total', 'sum')\n",
    "               ).reset_index().sort_values('event_completed')\n",
    "           )\n",
    "\n",
    "#Was the event a major?\n",
    "event_df['major'] = np.where(event_df['event_name'].isin(majors), 1, 0)\n",
    "\n",
    "#Did the golfer win the major?\n",
    "event_df['won_major'] = np.where((event_df['major'] == 1) & (event_df.fin_num == 1), 1, 0)\n",
    "\n",
    "#Did the golfer finish in the top 10?\n",
    "event_df['top_10'] = np.where(event_df['fin_num'] <= 10, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each desired metric, period combination\n",
    "#Calculate the rolling aggregation prior to a given event for each golfer\n",
    "#Add the calculated series to the event dataset as a new column\n",
    "for metric in metrics:\n",
    "    field = metric.get('field')\n",
    "    agg = metric.get('agg')\n",
    "    for period in metric.get('periods'):\n",
    "        col = f\"{field}_in_prev_{period}_events\"\n",
    "        event_df[col] = create_rolling_agg_features_by_golfer(event_df, field, 1, period, agg)\n",
    "        \n",
    "#filtering out events with no odds data\n",
    "event_df = event_df.loc[event_df.close_odds != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-sleep",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Inspecting the data and creating visuals to get a better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_in_dataset = len(event_df.year_event_id.unique())\n",
    "majors_in_dataset = len(event_df.query(\"major == 1\").year_event_id.unique())\n",
    "first_event_complete = event_df.event_completed.min()\n",
    "last_event_complete = event_df.event_completed.max()\n",
    "unique_golfers = len(event_df.dg_id.unique())\n",
    "\n",
    "print(f'There are {events_in_dataset} events in the dataset')\n",
    "print(f'{majors_in_dataset} of which are majors')\n",
    "print(f'Events span from {first_event_complete} to {last_event_complete}')\n",
    "print(f'A total of {unique_golfers} golfers have played in these events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-vintage",
   "metadata": {},
   "source": [
    "Taking a look at Strokes Gained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=event_df, x=\"total_sg\")\n",
    "plt.title('Total Strokes Gained per Event Histogram')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-emerald",
   "metadata": {},
   "source": [
    "Somewhat normally distributed and centered around 0.\n",
    "\n",
    "Looking at Scoring by whether it's a major or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping and aggregating strokes gained and events played by golfer\n",
    "golfer_sg = (event_df.groupby(['dg_id','player_name'])\n",
    "             .agg(total_sg = ('total_sg', 'sum'),\n",
    "                  events_played =('year_event_id', 'count')\n",
    "                 )\n",
    "            ).reset_index()\n",
    "\n",
    "#Creating strokes gained per event field\n",
    "golfer_sg['sg_per_event'] = golfer_sg['total_sg'] / golfer_sg['events_played']\n",
    "\n",
    "#Top 5 golfers by strokes gained per event\n",
    "#With at least 10 events played\n",
    "(golfer_sg.query(\"events_played >= 10\")\n",
    " .sort_values('sg_per_event', ascending = False)\n",
    " .head()\n",
    " .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottom 5golfers by strokes gained per event\n",
    "#With at least 10 events played\n",
    "(golfer_sg.query(\"events_played >= 10\")\n",
    " .sort_values('sg_per_event')\n",
    " .head()\n",
    " .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-brazil",
   "metadata": {},
   "source": [
    "Taking a look at whether strokes gained varies with a major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-detector",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data = event_df, x = 'major', y='total_sg')\\\n",
    ".set_title('Strokes gained')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-banana",
   "metadata": {},
   "source": [
    "Makes sense that the answer is **No** since strokes gained is a relative metric based on the event\n",
    "\n",
    "Taking a look at correlations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = event_df[feat_cols + [target_col]].corr()\n",
    "sns.heatmap(c, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-competition",
   "metadata": {},
   "source": [
    "It does appear that many of the lagging aggregate feature have correlations that are low to mid in strength.\n",
    "\n",
    "Close odds also has a pretty strong negative correlation at **-0.35**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-immunology",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the first 10 events of the dataset\n",
    "#This is necessary because of the lag features\n",
    "early_events_to_filter = event_df.sort_values('event_completed')['year_event_id'].unique()[0:11]\n",
    "event_df = (event_df.loc[~event_df.year_event_id.isin(early_events_to_filter)]\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "#splitting the data into independent (X) and dependent variables(y)\n",
    "X = event_df[feat_cols]\n",
    "\n",
    "y = event_df['total_sg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-equilibrium",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-photography",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fitting the model on the feature and target data\n",
    "lr = OLS(y, X).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-nerve",
   "metadata": {},
   "source": [
    "#### Checking assumptions for a linear model:\n",
    "    1. Must be linear in nature\n",
    "    2. Residuals are normally distributed\n",
    "    3. No Multicollinearity between predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "        \n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "    \n",
    "    # Calculating residuals for the plot\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "    \n",
    "    # Plotting the actual vs predicted values\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, size=7)\n",
    "        \n",
    "    # Plotting the diagonal line\n",
    "    line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "    plt.plot(line_coords, line_coords,  # X and y points\n",
    "             color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "linear_assumption(lr, X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-calvin",
   "metadata": {},
   "source": [
    "There is far from a perfect linear relationship here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(model, features, label):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def normal_errors_assumption(model, features, label, p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.diagnostic import normal_ad\n",
    "    print('Assumption 2: The error terms are normally distributed', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Anderson-Darling test\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "    p_value = normal_ad(df_results['Residuals'])[1]\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Residuals are not normally distributed')\n",
    "    else:\n",
    "        print('Residuals are normally distributed')\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    plt.title('Distribution of Residuals')\n",
    "    sns.distplot(df_results['Residuals'])\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    if p_value > p_value_thresh:\n",
    "        print('Assumption satisfied')\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        \n",
    "normal_errors_assumption(lr, X, y, p_value_thresh=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicollinearity_assumption(model, features, label, feature_names=None):\n",
    "    \"\"\"\n",
    "    Multicollinearity: Assumes that predictors are not correlated with each other. If there is\n",
    "                       correlation among the predictors, then either remove prepdictors with high\n",
    "                       Variance Inflation Factor (VIF) values or perform dimensionality reduction\n",
    "                           \n",
    "                       This assumption being violated causes issues with interpretability of the \n",
    "                       coefficients and the standard errors of the coefficients.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print('Assumption 3: Little to no multicollinearity among predictors')\n",
    "        \n",
    "    print('Variance Inflation Factors (VIF)')\n",
    "    print('> 10: An indication that multicollinearity may be present')\n",
    "    print('> 100: Certain multicollinearity among the variables')\n",
    "    print('-------------------------------------')\n",
    "       \n",
    "    # Gathering the VIF for each variable\n",
    "    VIF = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "    for idx, vif in enumerate(VIF):\n",
    "        print('{0}: {1}'.format(feature_names[idx], vif))\n",
    "        \n",
    "    # Gathering and printing total cases of possible or definite multicollinearity\n",
    "    possible_multicollinearity = sum([1 for vif in VIF if vif > 10])\n",
    "    definite_multicollinearity = sum([1 for vif in VIF if vif > 100])\n",
    "    print()\n",
    "    print('{0} cases of possible multicollinearity'.format(possible_multicollinearity))\n",
    "    print('{0} cases of definite multicollinearity'.format(definite_multicollinearity))\n",
    "    print()\n",
    "\n",
    "    if definite_multicollinearity == 0:\n",
    "        if possible_multicollinearity == 0:\n",
    "            print('Assumption satisfied')\n",
    "        else:\n",
    "            print('Assumption possibly satisfied')\n",
    "            print()\n",
    "            print('Coefficient interpretability may be problematic')\n",
    "\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Coefficient interpretability will be problematic')\n",
    "        \n",
    "multicollinearity_assumption(lr, X, y, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-vermont",
   "metadata": {},
   "source": [
    "## Fitting a Random Forest\n",
    "Since the linear regression assumptions were not satisfied, moving on to a less demanding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a Random Forest for Regression\n",
    "rf = RandomForestRegressor(n_estimators=300, min_samples_split=4, max_depth=10)\n",
    "\n",
    "#Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 42)\n",
    "\n",
    "#Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#Make a prediction on the test data\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds).round(3)\n",
    "print(f'Mean absolute error of {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df = (pd.DataFrame({'feature': X_train.columns, 'importance': rf.feature_importances_})\n",
    "               .sort_values('importance', ascending=False)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-reggae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(x ='importance', y='feature', data=feat_imp_df, color='green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the RF model\n",
    "pickle.dump(rf, open(\"../models/rf_model.pkl\", \"wb\"))\n",
    "\n",
    "#Write the event file for prediction on new data\n",
    "event_df.to_csv('../data/historical_event_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
